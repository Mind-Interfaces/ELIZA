{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-15T11:59:48.411873Z","iopub.execute_input":"2023-09-15T11:59:48.412295Z","iopub.status.idle":"2023-09-15T11:59:48.842187Z","shell.execute_reply.started":"2023-09-15T11:59:48.412245Z","shell.execute_reply":"2023-09-15T11:59:48.841075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nimport matplotlib.pyplot as plt\nimport json\n\n# Initialize an empty list to store the lines\nlines = []\n\n# Open the JSONL file and read the first few lines\nwith open('/kaggle/input/pippa-unfiltered/pippa_metharme.jsonl', 'r') as f:\n    for i, line in enumerate(f):\n        if i >= 5:  # Stop after reading 5 lines\n            break\n        lines.append(json.loads(line))\n\n# Convert the list of dictionaries to a Pandas DataFrame\ndf = pd.DataFrame(lines)\n\n# Display the head of the DataFrame\nprint(df.head())\n","metadata":{"execution":{"iopub.status.busy":"2023-09-15T13:33:24.173209Z","iopub.execute_input":"2023-09-15T13:33:24.174398Z","iopub.status.idle":"2023-09-15T13:33:24.224968Z","shell.execute_reply.started":"2023-09-15T13:33:24.174356Z","shell.execute_reply":"2023-09-15T13:33:24.223724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nimport seaborn as sns\n\nlines = []\nwith open('/kaggle/input/pippa-unfiltered/pippa_metharme.jsonl', 'r') as f:\n    for line in f:\n        lines.append(json.loads(line))\n\ndf = pd.DataFrame(lines)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-15T11:59:54.138777Z","iopub.execute_input":"2023-09-15T11:59:54.139230Z","iopub.status.idle":"2023-09-15T11:59:55.374045Z","shell.execute_reply.started":"2023-09-15T11:59:54.139192Z","shell.execute_reply":"2023-09-15T11:59:55.372554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Display basic information about the DataFrame\nprint(df.info())\n\n# Number of unique prompts\nnum_unique_prompts = df['prompt'].nunique()\nprint(f\"Number of unique prompts: {num_unique_prompts}\")\n\n# Average length of generations\navg_gen_length = df['generation'].apply(len).mean()\nprint(f\"Average length of generations: {avg_gen_length}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-15T11:59:56.887369Z","iopub.execute_input":"2023-09-15T11:59:56.888444Z","iopub.status.idle":"2023-09-15T11:59:57.593790Z","shell.execute_reply.started":"2023-09-15T11:59:56.888388Z","shell.execute_reply":"2023-09-15T11:59:57.592499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nimport pandas as pd\nfrom nltk.tokenize import sent_tokenize\n\n# Initialize an empty list to hold the individual sentences\nsentences_list = []\n\n# Iterate through each prompt and tokenize it into sentences\nfor prompt in df['prompt']:\n    sentences = sent_tokenize(prompt)\n    sentences_list.extend(sentences)\n\n# Create a new DataFrame with the individual sentences\ndf_sentences = pd.DataFrame(sentences_list, columns=['sentences'])\n\n# Show details of the new DataFrame\ndf_sentences.info()\ndf_sentences.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T12:00:08.793387Z","iopub.execute_input":"2023-09-15T12:00:08.793829Z","iopub.status.idle":"2023-09-15T12:02:26.099969Z","shell.execute_reply.started":"2023-09-15T12:00:08.793793Z","shell.execute_reply":"2023-09-15T12:02:26.098666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Filter for shorter entries and make a copy\ndf_short = df_sentences[df_sentences['sentences'].apply(len) < 100].copy()\n\n# Create a new column for text length\ndf_short['gen_length'] = df_short['sentences'].apply(len)\n\n# Plotting the distribution of text lengths\nsns.histplot(df_short['gen_length'], kde=True)\nplt.title('Distribution of Prompt Lengths')\nplt.xlabel('Text Length')\nplt.ylabel('Frequency')\nplt.show()\n\n# Show details of the new DataFrame\ndf_short.info()\ndf_short.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T12:03:13.514011Z","iopub.execute_input":"2023-09-15T12:03:13.514793Z","iopub.status.idle":"2023-09-15T12:03:24.771979Z","shell.execute_reply.started":"2023-09-15T12:03:13.514753Z","shell.execute_reply":"2023-09-15T12:03:24.770690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sample code to remove duplicates and check the structure of the DataFrame\n# This assumes 'df_sentences' is your DataFrame containing tokenized sentences.\n\n# Remove duplicate entries based on the 'sentences' column\ndf_short.drop_duplicates(subset=['sentences'], inplace=True)\n\n# Show basic information about the DataFrame after removing duplicates\ndf_short.info()\n\n# Show the first few entries for inspection\ndf_short.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T12:04:15.303494Z","iopub.execute_input":"2023-09-15T12:04:15.303896Z","iopub.status.idle":"2023-09-15T12:04:16.048026Z","shell.execute_reply.started":"2023-09-15T12:04:15.303862Z","shell.execute_reply":"2023-09-15T12:04:16.046885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Create a sample DataFrame for demonstration purposes\nimport re\n\n# Function to remove special characters like <|START|>, <|END|>, etc.\ndef clean_text(text):\n    return re.sub('<\\|.*?\\|>', '', text).strip()\n\n\n# Function to remove emojis and other special characters\ndef raw_text(text):\n    return re.sub('[^a-zA-Z0-9 \\n\\.]', '', text)\n\n# Apply the cleaning function\ndf_short['prompt'] = df_short['sentences'].apply(clean_text)\n\n\n# Apply the cleaning function to the 'sentences' column\ndataset = pd.DataFrame()\ndataset['prompt'] = df_short['prompt'].apply(raw_text)\n\n# Reindexing the DataFrame so that entry IDs match the row number\ndataset.reset_index(drop=True, inplace=True)\n\ndataset","metadata":{"execution":{"iopub.status.busy":"2023-09-15T12:09:18.266601Z","iopub.execute_input":"2023-09-15T12:09:18.267032Z","iopub.status.idle":"2023-09-15T12:09:26.562464Z","shell.execute_reply.started":"2023-09-15T12:09:18.267000Z","shell.execute_reply":"2023-09-15T12:09:26.561298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show details of the new DataFrame\ndataset.info()\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T12:09:36.082719Z","iopub.execute_input":"2023-09-15T12:09:36.083435Z","iopub.status.idle":"2023-09-15T12:09:36.267985Z","shell.execute_reply.started":"2023-09-15T12:09:36.083398Z","shell.execute_reply":"2023-09-15T12:09:36.266111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to check if a sentence is properly formed\ndef is_proper_sentence(sentence):\n    # Check for minimum length\n    if len(sentence) < 5:\n        return False\n    \n    # Check if the sentence starts with a capital letter\n    if not sentence[0].isupper():\n        return False\n    \n    # Check if the sentence ends with a full stop, question mark, or exclamation point\n    if sentence[-1] not in [\".\", \"?\", \"!\"]:\n        return False\n    \n    # Check for the presence of both a subject and a verb\n    # For this example, we will make a very rudimentary check by looking for spaces (indicative of multiple words)\n    if sentence.count(\" \") < 2:\n        return False\n    \n    return True\n\n# Filter the DataFrame\ndataset_filtered = dataset[dataset['prompt'].apply(is_proper_sentence)]\n# Reindexing the DataFrame so that entry IDs match the row number\ndataset_filtered.reset_index(drop=True, inplace=True)\n\n\ndataset_filtered","metadata":{"execution":{"iopub.status.busy":"2023-09-15T12:17:14.602596Z","iopub.execute_input":"2023-09-15T12:17:14.602995Z","iopub.status.idle":"2023-09-15T12:17:16.054808Z","shell.execute_reply.started":"2023-09-15T12:17:14.602964Z","shell.execute_reply":"2023-09-15T12:17:16.053068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DEPLOY ELIZA MENTOR @PROFESSOR_HENRY_HIGGINS","metadata":{}},{"cell_type":"code","source":"# ELIZA Keywords\n\n# Pre-substitution list\nPRES = {\n    \"don't\": \"dont\",\n    \"can't\": \"cant\",\n    \"won't\": \"wont\",\n    \"ain't\": \"aint\",\n    \"recollect\": \"remember\",\n    \"recall\": \"remember\",\n    \"dreamt\": \"dreamed\",\n    \"dreams\": \"dream\",\n    \"maybe\": \"perhaps\",\n    \"certainly\": \"yes\",\n    \"machine\": \"computer\",\n    \"machines\": \"computer\",\n    \"were\": \"was\",\n    \"you're\": \"you are\",\n    \"it's\": \"it is\",\n    \"i'm\": \"i am\",\n    \"same\": \"alike\",\n    \"identical\": \"alike\",\n    \"equivalent\": \"alike\"\n}\n\n# Post-substitution list\nPOSTS = {\n    \"am\": \"are\",\n    \"was\": \"were\",\n    \"i\": \"you\",\n    \"i'm\": \"you are\",\n    \"i'd\": \"you would\",\n    \"i've\": \"you have\",\n    \"i'll\": \"you will\",\n    \"my\": \"your\",\n    \"are\": \"am\",\n    \"you've\": \"I have\",\n    \"you'll\": \"I will\",\n    \"your\": \"my\",\n    \"yours\": \"mine\",\n    \"you\": \"I\",\n    \"me\": \"you\"\n}\n\n# Natural Language Toolkit: Keyword Pairs\nKEYWORDS = [\n    ['i desire (.*)', [\"Why do you need {0}?\", \"Would it really help you to get {0}?\", \"Are you sure you need {0}?\"]],\n    ['(.*) juice (.*)', [\"It's nice and sweet. It's a really good batch!\", \"I have blueberry juice, apple juice, lemon juice...\", \"It's really good. You're going to love it.\"]],\n    ['(.*) i forget (.*)', [\"Can you think of why you might forget {1}?\", \"Why can't you remember {1}?\", \"How often do you think of {1}?\", \"Does it bother you to forget that?\", \"Could it be a mental block?\", \"Are you generally forgetful?\", \"Do you think you are suppressing {1}?\"]],\n    ['(.*) did you forget (.*)', [\"Why do you ask?\", \"Are you sure you told me?\", \"Would it bother you if I forgot {1}?\", \"Why should I recall {1} just now?\", \"Tell me more about {1}.\"]],\n    ['(.*) name (.*)', [\"I am not interested in names.\", \"I've told you before, I don't care about names -- please continue.\"]],\n    ['why dont you ([^\\?]*)\\??', [\"Do you really think I don't {0}?\", \"Perhaps eventually I will {0}.\", \"Do you really want me to {0}?\"]],\n    ['why cant i ([^\\?]*)\\??', [\"Do you think you should be able to {0}?\", \"If you could {0}, what would you do?\", \"I don't know -- why can't you {0}?\", \"Have you really tried?\"]],\n    ['i cant (.*)', [\"How do you know you can't {0}?\", \"Perhaps you could {0} if you tried.\", \"What would it take for you to {0}?\"]],\n    ['(.*) i am sad (.*)', [\"I am sorry to hear that you are unhappy {1}.\", \"Do you think coming here will help you not to be depressed {1}?\", \"I'm sure it's not pleasant to be unhappy {1}.\", \"Can you explain what made you unhappy {1}?\", \"You sound really depressed.\", \"Do you feel inadequate because you are unhappy {1}?\"]],\n    ['i am (.*)', [\"Did you come to me because you are {0}?\", \"How long have you been {0}?\", \"How do you feel about being {0}?\"]],\n    ['im (.*)', [\"How does being {0} make you feel?\", \"Do you enjoy being {0}?\", \"Why do you tell me you're {0}?\", \"Why do you think you're {0}?\"]],\n    ['are you ([^\\?]*)\\??', [\"Why does it matter whether I am {0}?\", \"Would you prefer it if I were not {0}?\", \"Perhaps you believe I am {0}.\", \"I may be {0} -- what do you think?\", \"Why are you interested in whether I am {0} or not ?\", \"Would you prefer if I weren't {0} ?\", \"Perhaps I am {0} in your fantasies.\", \"Do you sometimes think I am {0} ?\", \"Would it matter to you ?\", \"What if I were {0} ?\"]],\n    ['what (.*)', [\"Why do you ask?\", \"How would an answer to that help you?\", \"What do you think?\", \"Does that question interest you?\", \"What is it you really want to know?\", \"Are such questions much on your mind?\", \"What answer would please you most?\", \"What comes to mind when you ask that?\", \"Have you asked such questions before?\", \"Have you asked anyone else?\"]],\n    ['how (.*)', [\"How do you suppose?\", \"Perhaps you can answer your own question.\", \"What is it you're really asking?\"]],\n    ['because (.*)', [\"Is that the real reason?\", \"What other reasons come to mind?\", \"Does that reason apply to anything else?\", \"If {0}, what else must be true?\", \"Is that the real reason?\", \"Don't any other reasons come to mind?\", \"Does that reason seem to explain anything else?\", \"What other reasons might there be?\"]],\n    ['(.*) sorry (.*)', [\"There are many times when no apology is needed.\", \"Apologies are not necessary.\", \"I have told you that apologies are not required.\",  \"It did not bother me.  Please continue.\", \"What feelings do you have when you apologize?\"]],\n    ['hello(.*)', [\"Hello... I'm glad you could drop by today.\", \"Hi there... how are you today?\", \"Hello, how are you feeling today?\"]],\n    ['i think (.*)', [\"Do you doubt {0}?\", \"Do you really think so?\", \"But you're not sure {0}?\"]],\n    ['(.*) friend (.*)', [\"Tell me more about your friends.\", \"When you think of a friend, what comes to mind?\", \"Why don't you tell me about a childhood friend?\"]],\n    ['yes', [\"You seem quite sure.\", \"OK, but can you elaborate a bit?\"]],\n    ['(.*) computer(.*)', [\"Are you really talking about me?\", \"Does it seem strange to talk to a computer?\", \"How do computers make you feel?\", \"Do you feel threatened by computers?\"]],\n    ['is it (.*)', [\"Do you think it is {0}?\", \"Perhaps it's {0} -- what do you think?\", \"If it were {0}, what would you do?\", \"It could well be that {0}.\"]],\n    ['it is (.*)', [\"You seem very certain.\", \"If I told you that it probably isn't {0}, what would you feel?\"]],\n    ['can you ([^\\?]*)\\??', [\"What makes you think I can't {0}?\", \"If I could {0}, then what?\", \"Why do you ask if I can {0}?\"]],\n    ['can i ([^\\?]*)\\??', [\"Perhaps you don't want to {0}.\", \"Do you want to be able to {0}?\", \"If you could {0}, would you?\"]],\n    ['you are (.*)', [\"Why do you think I am {0}?\", \"Does it please you to think that I am {0}?\", \"Perhaps you would like me to be {0}.\", \"Perhaps you're really talking about yourself?\"]],\n    ['youre (.*)', [\"Why do you say I am {0}?\", \"Why do you think I am {0}?\", \"Are we talking about you, or me?\"]],\n    ['i dont (.*)', [\"Don't you really {0}?\", \"Why don't you {0}?\", \"Do you want to {0}?\"]],\n    ['i feel (.*)', [\"Good, tell me more about these feelings.\", \"Do you often feel {0}?\", \"When do you usually feel {0}?\", \"When you feel {0}, what do you do?\"]],\n    ['i have (.*)', [\"Why do you tell me that you've {0}?\", \"Have you really {0}?\", \"Now that you have {0}, what will you do next?\"]],\n    ['i would (.*)', [\"Could you explain why you would {0}?\", \"Why would you {0}?\", \"Who else knows that you would {0}?\"]],\n    ['is there (.*)', [\"Do you think there is {0}?\", \"It's likely that there is {0}.\", \"Would you like there to be {0}?\"]],\n    ['my (.*)', [\"I see, your {0}.\", \"Why do you say that your {0}?\", \"When your {0}, how do you feel?\"]],\n    ['you (.*)', [\"We should be discussing you, not me.\", \"Why do you say that about me?\", \"Why do you care whether I {0}?\"]],\n    ['why (.*)', [\"Why don't you tell me the reason why {0}?\", \"Why do you think {0}?\"]],\n    ['why dont you (.*)', [\"Do you believe I do not {0}?\", \"Perhaps I will {0} in good time.\", \"Should you {0} yourself?\", \"You want me to {0}?\"]],\n    ['why cant i (.*)', [\"Do you think you should be able to {0}?\", \"Do you want to be able to {0}?\", \"Do you believe this will help you to {0}?\", \"Have you any idea why you can't {0}?\"]],\n    ['everyone (.*)', [\"Really, {0}?\", \"Surely not {0}.\", \"Can you think of anyone in particular?\", \"Who, for example?\", \"Are you thinking of a very special person?\", \"Who, may I ask?\", \"Someone special perhaps?\", \"You have a particular person in mind, yes?\", \"Who do you think you're talking about?\"]],\n    ['i want (.*)', [\"What would it mean to you if you got {0}?\", \"Why do you want {0}?\", \"What would you do if you got {0}?\", \"If you got {0}, then what would you do?\"]],\n    ['(.*) mother (.*)', [\"Tell me more about your mother.\", \"What was your relationship with your mother like?\", \"How do you feel about your mother?\", \"How does this relate to your feelings today?\", \"Good family relations are important.\"]],\n    ['(.*) father (.*)', [\"Tell me more about your father.\", \"How did your father make you feel?\", \"How do you feel about your father?\", \"Does your relationship with your father relate to your feelings today?\", \"Do you have trouble showing affection with your family?\"]],\n    ['(.*) child (.*)', [\"Did you have close friends as a child?\", \"What is your favorite childhood memory?\", \"Do you remember any dreams or nightmares from childhood?\", \"Did the other children sometimes tease you?\", \"How do you think your childhood experiences relate to your feelings today?\"]],\n    ['am i (.*)', [\"Do you believe you are {0}?\", \"Would you want to be {0}?\", \"Do you wish I would tell you you are {0}?\", \"What would it mean if you were {0}?\"]],\n    ['(.*) if (.*)', [\"Do you think it's likely that {1}?\", \"Do you wish that {1}?\", \"What do you know about {1}?\", \"Really, if {1}?\", \"What would you do if {1}?\", \"But what are the chances that {1}?\", \"What does this speculation lead to?\"]],\n    ['(.*) always (.*)', [\"Can you think of a specific example?\", \"When?\", \"What incident are you thinking of?\", \"Really, always?\"]],\n    ['(.*) alike', [\"In what way?\", \"What resemblance do you see?\", \"What does that similarity suggest to you?\", \"What other connections do you see?\", \"What do you suppose that resemblence means?\", \"What is the connection, do you suppose?\", \"Could there really be some connection?\", \"How?\"]],\n    ['like', [\"In what way?\", \"What resemblance do you see?\", \"What does that similarity suggest to you?\", \"What other connections do you see?\", \"What do you suppose that resemblence means?\", \"What is the connection, do you suppose?\", \"Could there really be some connection?\", \"How?\"]],\n    ['(.*) my family (.*)', [\"Tell me more about your family.\", \"Who else in your family {1}?\", \"Your {0}?\", \"What else comes to your mind when you think of your {1}?\"]],\n    ['(.*) my (.*)', [\"Your {1}?\", \"Why do you say your {1}?\", \"Is it important to you that your {1}?\"]],\n    ['(.*)?', [\"Why do you ask that?\", \"Please consider whether you can answer your own question.\", \"Perhaps the answer lies within yourself?\", \"Why don't you tell me?\"]],\n    ['(.*)', [\"Please tell me more.\", \"Let's change focus a bit... Tell me about your family.\", \"Can you elaborate on that?\", \"Why do you say that {0}?\", \"I see.\", \"Very interesting.\", \"{0}.\", \"I see.  And what does that tell you?\", \"How does that make you feel?\", \"How do you feel when you say that?\", \"I'm not sure I understand you fully.\", \"Please go on.\", \"What does that suggest to you?\", \"Do you feel strongly about discussing such things?\", \"That is interesting.  Please continue.\", \"Tell me more about that.\", \"Does talking about this bother you?\", \"Why not? You should have some more juice!\"]],\n]","metadata":{"execution":{"iopub.status.busy":"2023-09-15T12:21:56.774505Z","iopub.execute_input":"2023-09-15T12:21:56.775134Z","iopub.status.idle":"2023-09-15T12:21:56.807649Z","shell.execute_reply.started":"2023-09-15T12:21:56.775087Z","shell.execute_reply":"2023-09-15T12:21:56.806327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ELIZA Main Script - TEAM MIND INTERFACES (LABLAB 24-HOUR FINE-TUNING HACKATHON)\n\nimport re\nimport random\n\n\n# Function to apply pre-substitution on the statement\ndef pre(statement):\n    words = statement.lower().split()\n    for i, word in enumerate(words):\n        if word in PRES:\n            words[i] = PRES[word]\n    return ' '.join(words)\n\n# Function to apply post-substitution on the statement\ndef post(fragment):\n    words = fragment.lower().split()\n    for i, word in enumerate(words):\n        if word in POSTS:\n            words[i] = POSTS[word]\n    return ' '.join(words)\n\n# Function to analyze the statement and generate a response\ndef analyze(statement):\n    pre_statement = pre(statement)\n    for pattern, responses in KEYWORDS:\n        match = re.match(pattern, pre_statement.rstrip(\".!\"))\n        if match:\n            response = random.choice(responses)\n            return response.format(*[post(g) for g in match.groups()])","metadata":{"execution":{"iopub.status.busy":"2023-09-15T12:27:00.959320Z","iopub.execute_input":"2023-09-15T12:27:00.959938Z","iopub.status.idle":"2023-09-15T12:27:00.972350Z","shell.execute_reply.started":"2023-09-15T12:27:00.959882Z","shell.execute_reply":"2023-09-15T12:27:00.970910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfrom tqdm import tqdm\ntqdm.pandas()\n\n# Apply the 'analyze' function to the 'prompt' column to create a new 'generation' column, with a progress bar\n# dataset_filtered['generation'] = dataset_filtered['prompt'].progress_apply(analyze)\ndataset_filtered.loc[:, 'generation'] = dataset_filtered['prompt'].progress_apply(analyze)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-15T12:32:15.099600Z","iopub.execute_input":"2023-09-15T12:32:15.100043Z","iopub.status.idle":"2023-09-15T12:33:50.155693Z","shell.execute_reply.started":"2023-09-15T12:32:15.100004Z","shell.execute_reply":"2023-09-15T12:33:50.154254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_filtered","metadata":{"execution":{"iopub.status.busy":"2023-09-15T12:34:06.748140Z","iopub.execute_input":"2023-09-15T12:34:06.748592Z","iopub.status.idle":"2023-09-15T12:34:06.766714Z","shell.execute_reply.started":"2023-09-15T12:34:06.748558Z","shell.execute_reply":"2023-09-15T12:34:06.764920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n#CHECKPOINT\ndataset_filtered.to_json('ELIZA_dataset.json', orient='records', lines=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T13:14:12.725497Z","iopub.execute_input":"2023-09-15T13:14:12.725901Z","iopub.status.idle":"2023-09-15T13:14:15.800153Z","shell.execute_reply.started":"2023-09-15T13:14:12.725870Z","shell.execute_reply":"2023-09-15T13:14:15.799252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Make a copy to avoid SettingWithCopyWarning\ndataset_filtered_copy = dataset_filtered.copy()\n\n# Create a new column for text length\ndataset_filtered_copy['gen_length'] = dataset_filtered_copy['generation'].apply(len)\n\n# Plotting the distribution of text lengths\nsns.histplot(dataset_filtered_copy['gen_length'], kde=True)\nplt.title('Distribution of Response Lengths')\nplt.xlabel('Text Length')\nplt.ylabel('Frequency')\nplt.show()\n\n# Show details of the new DataFrame\ndataset_filtered_copy.info()\ndataset_filtered_copy.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-15T13:14:15.802583Z","iopub.execute_input":"2023-09-15T13:14:15.803070Z","iopub.status.idle":"2023-09-15T13:14:21.429518Z","shell.execute_reply.started":"2023-09-15T13:14:15.803025Z","shell.execute_reply":"2023-09-15T13:14:21.428074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Display the top 100 most frequent responses in the 'generation' column\ntop_10_responses = dataset_filtered_copy['generation'].value_counts().head(10)\ntop_10_responses","metadata":{"execution":{"iopub.status.busy":"2023-09-15T12:59:03.931335Z","iopub.execute_input":"2023-09-15T12:59:03.931730Z","iopub.status.idle":"2023-09-15T12:59:04.162356Z","shell.execute_reply.started":"2023-09-15T12:59:03.931700Z","shell.execute_reply":"2023-09-15T12:59:04.161014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Identify the rows that have the top 4 most frequent responses\nmask = dataset_filtered['generation'].isin([\n    'Why do you ask that?', \n    'Please consider whether you can answer your own question.',\n    'Perhaps the answer lies within yourself?',\n    'Why don\\'t you tell me?'\n])\n\n# Select those rows\ntop_4_df = dataset_filtered[mask]\n\n# Randomly sample 10% of those rows\ntop_4_df_reduced = top_4_df.sample(frac=0.1, random_state=1)\n\n# Select the rows that are not in the top 4 most frequent responses\nother_df = dataset_filtered[~mask]\n\n# Concatenate the reduced top 4 DataFrame with the other DataFrame\nbalanced_dataset = pd.concat([top_4_df_reduced, other_df]).reset_index(drop=True)\n\n# Show some details about the balanced dataset\nbalanced_dataset.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T13:07:01.797509Z","iopub.execute_input":"2023-09-15T13:07:01.797992Z","iopub.status.idle":"2023-09-15T13:07:02.164410Z","shell.execute_reply.started":"2023-09-15T13:07:01.797956Z","shell.execute_reply":"2023-09-15T13:07:02.163048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a copy to avoid SettingWithCopyWarning\ndataset_filtered_copy = balanced_dataset.copy()\n\n# Create a new column for text length\ndataset_filtered_copy['gen_length'] = dataset_filtered_copy['generation'].apply(len)\n\n# Plotting the distribution of text lengths\nsns.histplot(dataset_filtered_copy['gen_length'], kde=True)\nplt.title('Distribution of Response Lengths')\nplt.xlabel('Text Length')\nplt.ylabel('Frequency')\nplt.show()\n\n# Show details of the new DataFrame\ndataset_filtered_copy.info()\ndataset_filtered_copy.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T13:07:22.919187Z","iopub.execute_input":"2023-09-15T13:07:22.919643Z","iopub.status.idle":"2023-09-15T13:07:25.330036Z","shell.execute_reply.started":"2023-09-15T13:07:22.919609Z","shell.execute_reply":"2023-09-15T13:07:25.328760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Display the top 10 most frequent responses in the 'generation' column\ntop_10_responses = dataset_filtered_copy['generation'].value_counts().head(10)\ntop_10_responses","metadata":{"execution":{"iopub.status.busy":"2023-09-15T13:07:32.868729Z","iopub.execute_input":"2023-09-15T13:07:32.869323Z","iopub.status.idle":"2023-09-15T13:07:33.048362Z","shell.execute_reply.started":"2023-09-15T13:07:32.869233Z","shell.execute_reply":"2023-09-15T13:07:33.047100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of specific response pairs to reduce to approximately 1/7 of their current counts\nresponses_to_reduce_7th = [\n    \"Perhaps the answer lies within yourself?\",\n    \"Please consider whether you can answer your own question.\",\n    \"We should be discussing you, not me.\",\n    \"Why do you say that about me?\",\n    \"Why don't you tell me?\",\n    \"Why do you ask that?\"\n]\n\n# Reduce the frequency of these responses to approximately 1/7 of their current counts\ndataset_reduced_7th = dataset_filtered_copy.copy()\nfor response in responses_to_reduce_7th:\n    mask = dataset_reduced_7th['generation'] == response\n    rows_to_keep = dataset_reduced_7th[mask].sample(frac=1/7, random_state=1)\n    dataset_reduced_7th = pd.concat([dataset_reduced_7th[~mask], rows_to_keep])\n\n# Shuffle the dataset to mix the reduced rows with the rest\ndataset_reduced_7th = dataset_reduced_7th.sample(frac=1, random_state=1).reset_index(drop=True)\n\n# Display the number of entries after reduction\nlen(dataset_reduced_7th), dataset_reduced_7th['generation'].value_counts().head(10)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T13:13:47.775829Z","iopub.execute_input":"2023-09-15T13:13:47.776244Z","iopub.status.idle":"2023-09-15T13:13:48.695152Z","shell.execute_reply.started":"2023-09-15T13:13:47.776212Z","shell.execute_reply":"2023-09-15T13:13:48.693861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a copy to avoid SettingWithCopyWarning\ndataset_filtered_copy = dataset_reduced_7th.copy()\n\n# Create a new column for text length\ndataset_filtered_copy['gen_length'] = dataset_filtered_copy['generation'].apply(len)\n\n# Plotting the distribution of text lengths\nsns.histplot(dataset_filtered_copy['gen_length'], kde=True)\nplt.title('Distribution of Response Lengths')\nplt.xlabel('Text Length')\nplt.ylabel('Frequency')\nplt.show()\n\n# Show details of the new DataFrame\ndataset_filtered_copy.info()\ndataset_filtered_copy.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T13:13:54.170429Z","iopub.execute_input":"2023-09-15T13:13:54.171551Z","iopub.status.idle":"2023-09-15T13:13:56.405207Z","shell.execute_reply.started":"2023-09-15T13:13:54.171502Z","shell.execute_reply":"2023-09-15T13:13:56.404076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n#CHECKPOINT\ndataset_filtered_copy.to_json('ELIZA_INSTRUCT.json', orient='records', lines=True)","metadata":{},"execution_count":null,"outputs":[]}]}